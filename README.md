# llamachatbot
Developed a llama 3 chatbot in python by hosting an AI model locally. Did a seperate ui and backend that can be accessed on the given local network.  I used fast api to integrate my llama 3 to my UI as my pc cannot run both the UI and model at the same with limited VRAM, allowing me to think dynamically. I used this tutorial to better understand how to run llama 3 on hugging face.
https://youtu.be/7iAe3DmIXJY?si=0wnamFwMQv6RzexG
